{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cross1 BERT EN",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMUdlnBBcjHSpuEFgzl6MSn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "70b79f6c7a174ba1831873dde37eee0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_14476c04786048fd92ddf1308397ac65",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f2758494a8c44a39ae8070e62c1e2cd2",
              "IPY_MODEL_98177726142f44de80c4e3cea33595e6"
            ]
          }
        },
        "14476c04786048fd92ddf1308397ac65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f2758494a8c44a39ae8070e62c1e2cd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5b0b480e73784c7ebf913ec46a66a75f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7eea11a36cdd42d18b22397d84ae1562"
          }
        },
        "98177726142f44de80c4e3cea33595e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2cb98b94f9bf471089cea0957d0be528",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 702kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_36c82711959d46cea25085a33125f757"
          }
        },
        "5b0b480e73784c7ebf913ec46a66a75f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7eea11a36cdd42d18b22397d84ae1562": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2cb98b94f9bf471089cea0957d0be528": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "36c82711959d46cea25085a33125f757": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3c66cde686fd4218a6e640854714fae6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_eb5564a92d474a2dbd6ba54d1cef4ca2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d2735623f0294b7582abacfc0f13676d",
              "IPY_MODEL_50d84aca1431416c94c9a0099d9866f4"
            ]
          }
        },
        "eb5564a92d474a2dbd6ba54d1cef4ca2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d2735623f0294b7582abacfc0f13676d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_980d7a6fca734c1dae70af77817c09f9",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_69396cec3e1648d2a9d98fc1d1544e3d"
          }
        },
        "50d84aca1431416c94c9a0099d9866f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_03ab2a26f69348acbd8aeca5a200b216",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 2.83kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_feb876f4ee4e4ff2940f20bd35f64ca3"
          }
        },
        "980d7a6fca734c1dae70af77817c09f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "69396cec3e1648d2a9d98fc1d1544e3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "03ab2a26f69348acbd8aeca5a200b216": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "feb876f4ee4e4ff2940f20bd35f64ca3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "716994dc7f664c658508fa3a2777fdb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c6b54cc293e5420ebd3f830ec63d1d76",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_85959db8a7b340aa90a25f1ecb4dd8d6",
              "IPY_MODEL_da3b220d196f4404924491b801fe08ba"
            ]
          }
        },
        "c6b54cc293e5420ebd3f830ec63d1d76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "85959db8a7b340aa90a25f1ecb4dd8d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d5e6ac3cf8e5468e8b0d05d4436563ed",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_91b1d27d919847da9235fa30e981734c"
          }
        },
        "da3b220d196f4404924491b801fe08ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6ffb3b13cc13471aafc654a990d2ebeb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:06&lt;00:00, 64.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_99907335117046b38e915c89b12937f0"
          }
        },
        "d5e6ac3cf8e5468e8b0d05d4436563ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "91b1d27d919847da9235fa30e981734c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6ffb3b13cc13471aafc654a990d2ebeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "99907335117046b38e915c89b12937f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KristianMiok/Bayesian-BERT/blob/main/MCD%20BERT%20EN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzsLKo5evIKr",
        "outputId": "7236e894-5cec-4203-e4d2-9800909917ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_h6VIL4vcFo",
        "outputId": "3d3a1ca7-c657-4ccd-fd7b-14b3d9c84347",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrTt0fQRvgqf",
        "outputId": "0a8e8f68-a6fb-4afb-8214-33d30199ac22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 634
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/f4/9f93f06dd2c57c7cd7aa515ffbf9fcfd8a084b92285732289f4a5696dd91/transformers-3.2.0-py3-none-any.whl (1.0MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.0MB 4.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Collecting tokenizers==0.8.1.rc2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/83/8b9fccb9e48eeb575ee19179e2bdde0ee9a1904f97de5f02d19016b8804f/tokenizers-0.8.1rc2-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.0MB 23.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1MB 41.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 54.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=1603b0a23bd1159580b530c980c1af74cb024379e47c1d01f843831e81682681\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc2 transformers-3.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "or5q9M2jvjy-",
        "outputId": "3269ba38-0776-4e7c-c4b8-30d456786bd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9682 sha256=3358b99f6dd6a85cbcbd47f6d6ed0b9c88fe0c5987b1e30493a6dba6d3af155d\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rS3jcOW9hGx"
      },
      "source": [
        "# Our data set!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Sv9ofdu9jnt",
        "outputId": "0e29b2e2-88d8-419c-cc22-ff899ffceed1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Access to resources\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vomc06VCEy1H"
      },
      "source": [
        "# Read data from file\n",
        "import pandas as pd\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "# Point to the file in Google Drive\n",
        "filename='/content/gdrive/My Drive/big_dataset.csv'\n",
        "#filename='/content/gdrive/My Drive/EN_HS/big_dataset.csv'\n",
        "df = pd.read_csv(filename, sep=',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xsr_L9mE-YQ",
        "outputId": "b4655c6f-a36f-4066-c3df-3473670d03b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'label', 'tweet', 'normalized_text'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMt7yZRDj8Hq",
        "outputId": "e626649d-d192-4260-91a7-51da3af52693",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "df = df.reset_index(drop=True)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>normalized_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5964</td>\n",
              "      <td>0</td>\n",
              "      <td>@user #nbaupdates  #nbadraft  #cleveland    f...</td>\n",
              "      <td>nbaupdates nbadraft cleveland father day pleas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>15185</td>\n",
              "      <td>0</td>\n",
              "      <td>just saw tv commercial for @user milk. there's...</td>\n",
              "      <td>saw tv commercial milk nothing fair life dairy...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>23078</td>\n",
              "      <td>0</td>\n",
              "      <td>@user #gogirl #summer #camps #cardiff  #girls ...</td>\n",
              "      <td>gogirl summer camp cardiff girl confident book...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7989</td>\n",
              "      <td>0</td>\n",
              "      <td>collection launch on the 25th june @user   #a ...</td>\n",
              "      <td>collection launch th june bedford aist bluesky</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>15333</td>\n",
              "      <td>0</td>\n",
              "      <td>exciting times ahead!! #greatplacetowork #next...</td>\n",
              "      <td>excite time ahead nextchapter roydsllp withking</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  ...                                    normalized_text\n",
              "0   5964  ...  nbaupdates nbadraft cleveland father day pleas...\n",
              "1  15185  ...  saw tv commercial milk nothing fair life dairy...\n",
              "2  23078  ...  gogirl summer camp cardiff girl confident book...\n",
              "3   7989  ...     collection launch th june bedford aist bluesky\n",
              "4  15333  ...    excite time ahead nextchapter roydsllp withking\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWkvHqIyIr-2",
        "outputId": "0189cb76-cf39-4f50-a50c-c7b6ba4ee06f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "df1= shuffle(df, random_state=500)\n",
        "df1.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>normalized_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2187</th>\n",
              "      <td>5214</td>\n",
              "      <td>0</td>\n",
              "      <td>love love love being surprised... but i love s...</td>\n",
              "      <td>love love love surprised love surprising peopl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>3536</td>\n",
              "      <td>0</td>\n",
              "      <td>@user almost ready for the new addition to the...</td>\n",
              "      <td>almost ready new addition davis household dogf...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4973</th>\n",
              "      <td>31740</td>\n",
              "      <td>1</td>\n",
              "      <td>@user my video on the whole @user situation #b...</td>\n",
              "      <td>video whole situation boycottdelta expose trut...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>834</th>\n",
              "      <td>7388</td>\n",
              "      <td>0</td>\n",
              "      <td>south sudan unrest exacerbated by conflict amo...</td>\n",
              "      <td>south sudan unrest exacerbate conflict among c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1370</th>\n",
              "      <td>14917</td>\n",
              "      <td>0</td>\n",
              "      <td>fans didn't follow me back</td>\n",
              "      <td>fan not follow back</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id  ...                                    normalized_text\n",
              "2187   5214  ...  love love love surprised love surprising peopl...\n",
              "116    3536  ...  almost ready new addition davis household dogf...\n",
              "4973  31740  ...  video whole situation boycottdelta expose trut...\n",
              "834    7388  ...  south sudan unrest exacerbate conflict among c...\n",
              "1370  14917  ...                                fan not follow back\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAhN2g8AlGlD",
        "outputId": "00f2bd89-c3d4-4242-e17f-c6ec642d5d45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "df2 = df1.reset_index(drop=True)\n",
        "df2.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>normalized_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5214</td>\n",
              "      <td>0</td>\n",
              "      <td>love love love being surprised... but i love s...</td>\n",
              "      <td>love love love surprised love surprising peopl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3536</td>\n",
              "      <td>0</td>\n",
              "      <td>@user almost ready for the new addition to the...</td>\n",
              "      <td>almost ready new addition davis household dogf...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>31740</td>\n",
              "      <td>1</td>\n",
              "      <td>@user my video on the whole @user situation #b...</td>\n",
              "      <td>video whole situation boycottdelta expose trut...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7388</td>\n",
              "      <td>0</td>\n",
              "      <td>south sudan unrest exacerbated by conflict amo...</td>\n",
              "      <td>south sudan unrest exacerbate conflict among c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>14917</td>\n",
              "      <td>0</td>\n",
              "      <td>fans didn't follow me back</td>\n",
              "      <td>fan not follow back</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  ...                                    normalized_text\n",
              "0   5214  ...  love love love surprised love surprising peopl...\n",
              "1   3536  ...  almost ready new addition davis household dogf...\n",
              "2  31740  ...  video whole situation boycottdelta expose trut...\n",
              "3   7388  ...  south sudan unrest exacerbate conflict among c...\n",
              "4  14917  ...                                fan not follow back\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blvnwjmSRp3q"
      },
      "source": [
        "train = pd.DataFrame(df2.iloc[:4000,:])\n",
        "test = pd.DataFrame(df2.iloc[4000:,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBnumouKvxqX"
      },
      "source": [
        "# Get the lists of sentences and their labels.\n",
        "sentences = train.tweet.values\n",
        "labels = train.label.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDlym6r9v0_n",
        "outputId": "32bd7702-cff1-43e3-f05d-579c56d8315f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "70b79f6c7a174ba1831873dde37eee0b",
            "14476c04786048fd92ddf1308397ac65",
            "f2758494a8c44a39ae8070e62c1e2cd2",
            "98177726142f44de80c4e3cea33595e6",
            "5b0b480e73784c7ebf913ec46a66a75f",
            "7eea11a36cdd42d18b22397d84ae1562",
            "2cb98b94f9bf471089cea0957d0be528",
            "36c82711959d46cea25085a33125f757"
          ]
        }
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "70b79f6c7a174ba1831873dde37eee0b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eNSbQmGv6tf",
        "outputId": "dac66ef5-a960-4487-e167-136aaf1cd311",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', sentences[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  love love love being surprised... but i love surprising people even more  \n",
            "Tokenized:  ['love', 'love', 'love', 'being', 'surprised', '.', '.', '.', 'but', 'i', 'love', 'surprising', 'people', 'even', 'more']\n",
            "Token IDs:  [2293, 2293, 2293, 2108, 4527, 1012, 1012, 1012, 2021, 1045, 2293, 11341, 2111, 2130, 2062]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNeXWOGcwHGP",
        "outputId": "e9e08cfc-3e53-4109-986f-75ab7717ed94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "\n",
        "                        # This function also supports truncation and conversion\n",
        "                        # to pytorch tensors, but we need to do padding, so we\n",
        "                        # can't use these features :( .\n",
        "                        #max_length = 128,          # Truncate all sentences.\n",
        "                        #return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[1])\n",
        "print('Token IDs:', input_ids[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  @user almost ready for the new addition to the davis household   #dogforlife \n",
            "Token IDs: [101, 1030, 5310, 2471, 3201, 2005, 1996, 2047, 2804, 2000, 1996, 4482, 4398, 1001, 3899, 29278, 15509, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDufI5aVwJuH",
        "outputId": "ff223f66-8554-411b-ec45-7ba92672a2b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Max sentence length: ', max([len(sen) for sen in input_ids]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  55\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9aO0sr2wNO4",
        "outputId": "c32bbc4f-3385-40ad-a8a3-fff3fc365ac1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# We'll borrow the `pad_sequences` utility function to do this.\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Set the maximum sequence length.\n",
        "# I've chosen 64 somewhat arbitrarily. It's slightly larger than the\n",
        "# maximum training sentence length of 47...\n",
        "MAX_LEN = 64\n",
        "\n",
        "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
        "\n",
        "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "# Pad our input tokens with value 0.\n",
        "# \"post\" indicates that we want to pad and truncate at the end of the sequence,\n",
        "# as opposed to the beginning.\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print('\\nDone.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Padding/truncating all sentences to 64 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90_U5qV8wRYv"
      },
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# For each sentence...\n",
        "for sent in input_ids:\n",
        "    \n",
        "    # Create the attention mask.\n",
        "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
        "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    \n",
        "    # Store the attention mask for this sentence.\n",
        "    attention_masks.append(att_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ucc-52MwUg_"
      },
      "source": [
        "# Use train_test_split to split our data into train and validation sets for\n",
        "# training\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use 80% for training and 10% for validation.\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
        "                                                            random_state=2018, test_size=0.1)\n",
        "# Do the same for the masks.\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
        "                                             random_state=2018, test_size=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29wced1HwXlg"
      },
      "source": [
        "# Convert all inputs and labels into torch tensors, the required datatype \n",
        "# for our model.\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKm3pv0UwbzA"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here.\n",
        "# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n",
        "# 16 or 32.\n",
        "\n",
        "# We set all of the tweets into the batches\n",
        "batch_size = 8\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsugQQf3wikg",
        "outputId": "efc93b0f-ded0-45fc-b240-be1cf7443852",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "train_inputs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  101,  2047,  2733,  ...,     0,     0,     0],\n",
              "        [  101,  3232,  2383,  ...,     0,     0,     0],\n",
              "        [  101,  1001,  6209,  ...,     0,     0,     0],\n",
              "        ...,\n",
              "        [  101,  1030,  5310,  ...,     0,     0,     0],\n",
              "        [  101,  6289, 23644,  ...,     0,     0,     0],\n",
              "        [  101,  1996, 13521,  ...,     0,     0,     0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHHRQfisUeV2",
        "outputId": "62de8acf-2a22-48bd-abad-13dec483e29a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "3c66cde686fd4218a6e640854714fae6",
            "eb5564a92d474a2dbd6ba54d1cef4ca2",
            "d2735623f0294b7582abacfc0f13676d",
            "50d84aca1431416c94c9a0099d9866f4",
            "980d7a6fca734c1dae70af77817c09f9",
            "69396cec3e1648d2a9d98fc1d1544e3d",
            "03ab2a26f69348acbd8aeca5a200b216",
            "feb876f4ee4e4ff2940f20bd35f64ca3",
            "716994dc7f664c658508fa3a2777fdb9",
            "c6b54cc293e5420ebd3f830ec63d1d76",
            "85959db8a7b340aa90a25f1ecb4dd8d6",
            "da3b220d196f4404924491b801fe08ba",
            "d5e6ac3cf8e5468e8b0d05d4436563ed",
            "91b1d27d919847da9235fa30e981734c",
            "6ffb3b13cc13471aafc654a990d2ebeb",
            "99907335117046b38e915c89b12937f0"
          ]
        }
      },
      "source": [
        "# Loading BERT that we need!\n",
        "\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "    #mnum_labels = 1, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3c66cde686fd4218a6e640854714fae6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "716994dc7f664c658508fa3a2777fdb9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gO_wjqWxOLI",
        "outputId": "7f2e3195-8406-427e-e520-5d9b1f14eab3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        }
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (2, 768)\n",
            "classifier.bias                                                 (2,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSPHYndSy6a2"
      },
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2g6BsrKy9TB"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZrSSNOOzJsJ"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Tna72gHzSaB"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0gtycLSzZ4E",
        "outputId": "dd1f119a-8093-4afa-dbd8-428344a68474",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Fine tuning!\n",
        "\n",
        "import random\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Store the average loss after each epoch so we can plot them.\n",
        "loss_values = []\n",
        "\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # This will return the loss (rather than the model output) because we\n",
        "        # have provided the `labels`.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        outputs = model(b_input_ids, \n",
        "                    token_type_ids=None, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)\n",
        "        \n",
        "        # The call to `model` always returns a tuple, so we need to pull the \n",
        "        # loss value out of the tuple.\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # Telling the model not to compute or store gradients, saving memory and\n",
        "        # speeding up validation\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have\n",
        "            # not provided labels.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    450.    Elapsed: 0:00:05.\n",
            "  Batch    80  of    450.    Elapsed: 0:00:10.\n",
            "  Batch   120  of    450.    Elapsed: 0:00:16.\n",
            "  Batch   160  of    450.    Elapsed: 0:00:21.\n",
            "  Batch   200  of    450.    Elapsed: 0:00:26.\n",
            "  Batch   240  of    450.    Elapsed: 0:00:31.\n",
            "  Batch   280  of    450.    Elapsed: 0:00:37.\n",
            "  Batch   320  of    450.    Elapsed: 0:00:42.\n",
            "  Batch   360  of    450.    Elapsed: 0:00:47.\n",
            "  Batch   400  of    450.    Elapsed: 0:00:53.\n",
            "  Batch   440  of    450.    Elapsed: 0:00:58.\n",
            "\n",
            "  Average training loss: 0.40\n",
            "  Training epcoh took: 0:00:59\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.88\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    450.    Elapsed: 0:00:05.\n",
            "  Batch    80  of    450.    Elapsed: 0:00:10.\n",
            "  Batch   120  of    450.    Elapsed: 0:00:16.\n",
            "  Batch   160  of    450.    Elapsed: 0:00:21.\n",
            "  Batch   200  of    450.    Elapsed: 0:00:26.\n",
            "  Batch   240  of    450.    Elapsed: 0:00:31.\n",
            "  Batch   280  of    450.    Elapsed: 0:00:36.\n",
            "  Batch   320  of    450.    Elapsed: 0:00:41.\n",
            "  Batch   360  of    450.    Elapsed: 0:00:46.\n",
            "  Batch   400  of    450.    Elapsed: 0:00:52.\n",
            "  Batch   440  of    450.    Elapsed: 0:00:57.\n",
            "\n",
            "  Average training loss: 0.21\n",
            "  Training epcoh took: 0:00:58\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.88\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    450.    Elapsed: 0:00:05.\n",
            "  Batch    80  of    450.    Elapsed: 0:00:10.\n",
            "  Batch   120  of    450.    Elapsed: 0:00:16.\n",
            "  Batch   160  of    450.    Elapsed: 0:00:21.\n",
            "  Batch   200  of    450.    Elapsed: 0:00:26.\n",
            "  Batch   240  of    450.    Elapsed: 0:00:31.\n",
            "  Batch   280  of    450.    Elapsed: 0:00:36.\n",
            "  Batch   320  of    450.    Elapsed: 0:00:41.\n",
            "  Batch   360  of    450.    Elapsed: 0:00:46.\n",
            "  Batch   400  of    450.    Elapsed: 0:00:51.\n",
            "  Batch   440  of    450.    Elapsed: 0:00:57.\n",
            "\n",
            "  Average training loss: 0.09\n",
            "  Training epcoh took: 0:00:58\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.88\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    450.    Elapsed: 0:00:05.\n",
            "  Batch    80  of    450.    Elapsed: 0:00:10.\n",
            "  Batch   120  of    450.    Elapsed: 0:00:15.\n",
            "  Batch   160  of    450.    Elapsed: 0:00:20.\n",
            "  Batch   200  of    450.    Elapsed: 0:00:26.\n",
            "  Batch   240  of    450.    Elapsed: 0:00:31.\n",
            "  Batch   280  of    450.    Elapsed: 0:00:36.\n",
            "  Batch   320  of    450.    Elapsed: 0:00:41.\n",
            "  Batch   360  of    450.    Elapsed: 0:00:46.\n",
            "  Batch   400  of    450.    Elapsed: 0:00:51.\n",
            "  Batch   440  of    450.    Elapsed: 0:00:56.\n",
            "\n",
            "  Average training loss: 0.04\n",
            "  Training epcoh took: 0:00:57\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.89\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLclGr7XMF-G"
      },
      "source": [
        "torch.save(model.state_dict(), \"/content/gdrive/My Drive/EN_HS/model\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gWudLFuNdno"
      },
      "source": [
        "#model = TheModelClass(*args, **kwargs)\n",
        "model.load_state_dict(torch.load('/content/gdrive/My Drive/EN_HS/model'))\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpS2P37_1PXF",
        "outputId": "89a54af4-72e2-41d1-bb12-91d0c58356b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(loss_values, 'b-o')\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBm8rA6y1jyU",
        "outputId": "caffb743-6d60-4bad-f032-6d62c1e705c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Test Dataset!\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "#df = pd.read_csv(\"./cola_public/raw/out_of_domain_dev.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "df= test\n",
        "# Report the number of sentences.\n",
        "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Create sentence and label lists\n",
        "sentences = test.tweet.values\n",
        "labels = test.label.values\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                   )\n",
        "    \n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Pad our input tokens\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, \n",
        "                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask) \n",
        "\n",
        "# Convert to tensors.\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 8\n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, \n",
        "                                   sampler=prediction_sampler,\n",
        "                                   batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of test sentences: 1,000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdwyaVR025ge"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def softmax(x):\n",
        "\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "\n",
        "    return e_x / e_x.sum()\n",
        "\n",
        "from scipy.special import softmax    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WalBbo9eIi1W",
        "outputId": "7ce0476c-8000-49a2-a701-8cc892d72536",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "y= pd.DataFrame()\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  pred=[]\n",
        "  collect=[]\n",
        "  p=[]\n",
        "  #w=[]\n",
        "  w = pd.DataFrame()\n",
        "\n",
        "  model.train()\n",
        "  pred = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "  p=pred[0].detach().cpu().numpy()\n",
        "  x = np.reshape(p, (8, 2))\n",
        "  x = pd.DataFrame(x)\n",
        "  x2 = softmax(x, axis=1)\n",
        "  x3 = x2.drop([0], axis=1)\n",
        "  y = y.append(x3)\n",
        "  # w = pd.concat([w, x3], axis=1, ignore_index=True)\n",
        "\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 1,000 test sentences...\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pued2jGV5mCN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9eBVKJRIpki",
        "outputId": "a1c0198a-a7fa-4a34-ca61-b7d3c672bd6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Positive samples: %d of %d (%.2f%%)' % (df.label.sum(), len(df.label), (df.label.sum() / len(df.label) * 100.0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive samples: 465 of 1000 (46.50%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vV4SA9V2Fz0"
      },
      "source": [
        "# predictions = pd.DataFrame(predictions)\n",
        "# predictions.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yv6orThL3GzK"
      },
      "source": [
        "x2 = softmax(predictions, axis=1)\n",
        "#x3 = x2.drop([0], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBL68dOBIuPT",
        "outputId": "aa1380d5-938d-4584-f919-b26f97265d7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "matthews_set = []\n",
        "\n",
        "# Evaluate each test batch using Matthew's correlation coefficient\n",
        "print('Calculating Matthews Corr. Coef. for each batch...')\n",
        "\n",
        "# For each input batch...\n",
        "for i in range(len(true_labels)):\n",
        "  \n",
        "  # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
        "  # and one column for \"1\"). Pick the label with the highest value and turn this\n",
        "  # in to a list of 0s and 1s.\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "  \n",
        "  # Calculate and store the coef for this batch.  \n",
        "  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n",
        "  matthews_set.append(matthews)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calculating Matthews Corr. Coef. for each batch...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:900: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4_uPYkRI04s",
        "outputId": "7b76b26c-d29d-4020-c309-31d18bd46296",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "matthews_set"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0,\n",
              " 0.2581988897471611,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.5773502691896258,\n",
              " 0.4879500364742666,\n",
              " 0.6546536707079772,\n",
              " 1.0,\n",
              " 0.7453559924999299,\n",
              " 1.0,\n",
              " 0.7453559924999299,\n",
              " 1.0,\n",
              " 0.4666666666666667,\n",
              " 0.6,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.7745966692414834,\n",
              " 0.5773502691896258,\n",
              " 1.0,\n",
              " 0.5773502691896258,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.7453559924999299,\n",
              " 0.2581988897471611,\n",
              " 1.0,\n",
              " 0.7745966692414834,\n",
              " 1.0,\n",
              " 0.4879500364742666,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.6,\n",
              " 0.6546536707079772,\n",
              " 1.0,\n",
              " 0.7453559924999299,\n",
              " 0.7745966692414834,\n",
              " 0.2581988897471611,\n",
              " 0.7453559924999299,\n",
              " 0.7745966692414834,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.7453559924999299,\n",
              " 1.0,\n",
              " 0.7453559924999299,\n",
              " 0.6546536707079772,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.7745966692414834,\n",
              " 0.7453559924999299,\n",
              " 0.7745966692414834,\n",
              " 0.5,\n",
              " 0.6,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.7453559924999299,\n",
              " 0.7745966692414834,\n",
              " 1.0,\n",
              " 0.7745966692414834,\n",
              " 0.5,\n",
              " 0.7453559924999299,\n",
              " 1.0,\n",
              " 0.3333333333333333,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.7745966692414834,\n",
              " 0.6,\n",
              " 1.0,\n",
              " 0.7453559924999299,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.5773502691896258,\n",
              " 0.7745966692414834,\n",
              " 0.7745966692414834,\n",
              " 0.7745966692414834,\n",
              " 1.0,\n",
              " 0.4879500364742666,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.6546536707079772,\n",
              " 0.7745966692414834,\n",
              " 1.0,\n",
              " 0.7745966692414834,\n",
              " 0.7745966692414834,\n",
              " 0.6546536707079772,\n",
              " 0.5773502691896258,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.6,\n",
              " 0.7745966692414834,\n",
              " 0.7453559924999299,\n",
              " 0.0,\n",
              " 0.7745966692414834,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.7453559924999299,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.4472135954999579,\n",
              " -0.14285714285714285,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.5773502691896258,\n",
              " 0.7745966692414834,\n",
              " 0.7453559924999299,\n",
              " 1.0,\n",
              " 0.6546536707079772,\n",
              " 1.0,\n",
              " 0.4879500364742666,\n",
              " 1.0,\n",
              " 0.7453559924999299,\n",
              " 1.0,\n",
              " 0.7453559924999299]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9CNxp3rJLKt",
        "outputId": "ad921a0b-81af-40a8-df31-0b7cadac05d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Combine the predictions for each batch into a single list of 0s and 1s.\n",
        "flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
        "\n",
        "# Calculate the MCC\n",
        "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "\n",
        "print('MCC: %.3f' % mcc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MCC: 0.807\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gwh4Ogu2ocz",
        "outputId": "4779e851-3218-49ba-a4c8-932b3544dfbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 825
        }
      },
      "source": [
        "flat_predictions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0,\n",
              "       1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1,\n",
              "       1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
              "       0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "       1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
              "       1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1,\n",
              "       1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "       1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0,\n",
              "       1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1,\n",
              "       1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1,\n",
              "       1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0,\n",
              "       0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1,\n",
              "       0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0,\n",
              "       0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "       1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1,\n",
              "       0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1,\n",
              "       0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0,\n",
              "       1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n",
              "       0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1,\n",
              "       1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0,\n",
              "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1,\n",
              "       1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0,\n",
              "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "       0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1,\n",
              "       0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
              "       1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1,\n",
              "       0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1,\n",
              "       0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0,\n",
              "       1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1,\n",
              "       0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
              "       0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
              "       1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1,\n",
              "       0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1,\n",
              "       0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
              "       1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
              "       1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0,\n",
              "       0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
              "       0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
              "       0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0,\n",
              "       0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1,\n",
              "       0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1,\n",
              "       1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "       1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1,\n",
              "       1, 1, 1, 0, 1, 1, 1, 0, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1eXiaANWVgb"
      },
      "source": [
        "flat_true_labels= pd.DataFrame(flat_true_labels)\n",
        "flat_predictions= pd.DataFrame(flat_predictions) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39lvPuvWjzRX",
        "outputId": "a9718c29-2f96-450c-c34d-9247910cbf5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test = pd.DataFrame(test)\n",
        "\n",
        "test=test.reset_index(drop=True)\n",
        "\n",
        "test.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'label', 'tweet', 'normalized_text'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGHGQLH36bw7"
      },
      "source": [
        "true= test['label']\n",
        "true\n",
        "y= y.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OQmp574tlOA",
        "outputId": "1e02b3bf-933d-4df4-c625-2cf8c8b54563",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "text=test['tweet']\n",
        "text= pd.DataFrame(text)\n",
        "text=text.reset_index(drop=True)\n",
        "text.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOEg6KyxjfQV",
        "outputId": "39d3600e-147c-4d18-887f-64fbe9913473",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        }
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000285</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.001988</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000841</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.999228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>0.999527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>0.999129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>0.000602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>0.998974</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>0.999288</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows Ã— 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            1\n",
              "0    0.000672\n",
              "1    0.000285\n",
              "2    0.001988\n",
              "3    0.000841\n",
              "4    0.999228\n",
              "..        ...\n",
              "995  0.999527\n",
              "996  0.999129\n",
              "997  0.000602\n",
              "998  0.998974\n",
              "999  0.999288\n",
              "\n",
              "[1000 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAE90wLC8EY3"
      },
      "source": [
        "result = pd.concat([y, true], axis=1, sort=False)\n",
        "#result = pd.concat([flat_true_labels, y], axis=1, ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLJKh24l6M-s",
        "outputId": "7dda03a5-7b0e-4671-a168-5046189c674b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "result.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsA_mfuTjkvJ"
      },
      "source": [
        "result = pd.concat([flat_true_labels,flat_predictions], axis=1, sort=False)\n",
        "#result = pd.concat([test, y], axis=1, ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2RIhVGtXG7u",
        "outputId": "9e54b22f-647a-4599-cdda-f2380762d0a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        }
      },
      "source": [
        "result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     0  0\n",
              "0    0  0\n",
              "1    0  0\n",
              "2    0  0\n",
              "3    0  0\n",
              "4    1  1\n",
              "..  .. ..\n",
              "995  1  1\n",
              "996  1  1\n",
              "997  0  0\n",
              "998  1  1\n",
              "999  0  1\n",
              "\n",
              "[1000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oF3PEqEzWFs"
      },
      "source": [
        "# result.to_csv(r'/content/gdrive/My Drive/EN_HS/only_pred.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFgUBe6b2Cma"
      },
      "source": [
        " #flat_accuracy(predictions, true_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDE6G4JG4tTk",
        "outputId": "f7498b7f-a249-4859-cbbf-ea79d6a96ee3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Positive samples: %d of %d (%.2f%%)' % (df.label.sum(), len(df.label), (df.label.sum() / len(df.label) * 100.0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive samples: 465 of 1000 (46.50%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Irq867EaUCnQ",
        "outputId": "f9430f39-3b7e-4b33-be69-68793064b592",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "accuracies_set = []\n",
        "\n",
        "# Evaluate each test batch using Matthew's correlation coefficient\n",
        "print('Calculating Matthews Corr. Coef. for each batch...')\n",
        "\n",
        "# For each input batch...\n",
        "for i in range(len(true_labels)):\n",
        "  \n",
        "  # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
        "  # and one column for \"1\"). Pick the label with the highest value and turn this\n",
        "  # in to a list of 0s and 1s.\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "  \n",
        "  # Calculate and store the coef for this batch.\n",
        "  #matthews = matthews_corrcoef(true_labels[i], pred_labels_i)\n",
        "  accuracy = accuracy_score(true_labels[i], pred_labels_i)                \n",
        "  accuracies_set.append(accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calculating Matthews Corr. Coef. for each batch...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrrisEwIULSX",
        "outputId": "13bcdf16-b944-4be1-b440-821091c4bfef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "accuracies_set"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0,\n",
              " 0.625,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.75,\n",
              " 0.75,\n",
              " 0.875,\n",
              " 1.0,\n",
              " 0.875,\n",
              " 1.0,\n",
              " 0.875,\n",
              " 1.0,\n",
              " 0.75,\n",
              " 0.75,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.875,\n",
              " 0.75,\n",
              " 1.0,\n",
              " 0.75,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.875,\n",
              " 0.625,\n",
              " 1.0,\n",
              " 0.875,\n",
              " 1.0,\n",
              " 0.75,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.75,\n",
              " 0.875,\n",
              " 1.0,\n",
              " 0.875,\n",
              " 0.875,\n",
              " 0.625,\n",
              " 0.875,\n",
              " 0.875,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.875,\n",
              " 1.0,\n",
              " 0.875,\n",
              " 0.875,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.875,\n",
              " 0.875,\n",
              " 0.875,\n",
              " 0.75,\n",
              " 0.75,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.875,\n",
              " 0.875,\n",
              " 1.0,\n",
              " 0.875,\n",
              " 0.75,\n",
              " 0.875,\n",
              " 1.0,\n",
              " 0.75,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.875,\n",
              " 0.75,\n",
              " 1.0,\n",
              " 0.875,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.75,\n",
              " 0.875,\n",
              " 0.875,\n",
              " 0.875,\n",
              " 1.0,\n",
              " 0.75,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.875,\n",
              " 0.875,\n",
              " 1.0,\n",
              " 0.875,\n",
              " 0.875,\n",
              " 0.875,\n",
              " 0.75,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.75,\n",
              " 0.875,\n",
              " 0.875,\n",
              " 0.875,\n",
              " 0.875,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.875,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.625,\n",
              " 0.75,\n",
              " 0.5,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.75,\n",
              " 0.875,\n",
              " 0.875,\n",
              " 1.0,\n",
              " 0.875,\n",
              " 1.0,\n",
              " 0.75,\n",
              " 1.0,\n",
              " 0.875,\n",
              " 1.0,\n",
              " 0.875]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxP9zgdSUPaj",
        "outputId": "0d74a6e2-6790-4cfe-911d-dea024252036",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "\n",
        "# Combine the predictions for each batch into a single list of 0s and 1s.\n",
        "flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
        "\n",
        "# Calculate the Acc\n",
        "#mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "acc = accuracy_score(flat_true_labels, flat_predictions)\n",
        "pre = precision_score(flat_true_labels, flat_predictions)\n",
        "rec = recall_score(flat_true_labels, flat_predictions)\n",
        "f1 = f1_score(flat_true_labels, flat_predictions)\n",
        "\n",
        "print('ACC: %.3f' % acc)\n",
        "print('PRE: %.3f' % pre)\n",
        "print('REC: %.3f' % rec)\n",
        "print('F1: %.3f' % f1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ACC: 0.903\n",
            "PRE: 0.874\n",
            "REC: 0.925\n",
            "F1: 0.899\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}